---
title: "Car Analysis | Predicting selling point"
author: "Tonatiuh De Leon"
output: 
  html_document:
    theme: default
    code_folding: hide
    keep_md: true
editor_options: 
  chunk_output_type: console
---

<br>

This analysis will use a linear model to predict the selling price of my vehicle when it reaches 220,000 miles, assuming an annual usage of 20,000 to 25,000 miles. To estimate the selling price, I will fit a simple regression model shown below, and then we will analyze its results to determine if it is reliable.

<br>

$$
  \underbrace{{Y}_i}_\text{Predicted Price} = \overbrace{b_0}^\text{est. y-int} + \overbrace{b_1}^\text{est. slope} \underbrace{X_i}_\text{Mileage}
$$ 
$$
\text{.05 Alpha Level Considered for Slopes and Intercepts Statistical Significance} 
$$

<br> 

When performing the regression analysis on this data, I noticed that a Box-Cox transformation was recommended. Therefore, I proceeded to model both a simple linear model and the transformed version. The transformed model, incidentally, turned out to be the better of the two. You can find the details for both models in the tabs below.

<br>

##  {.tabset .tabset-pills .tabset-fade}

### Transformed Linear Model

<br>

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', fig.width=10}

library(tidyverse)
library(MASS)
library(pander)
library(ggrepel)

car_analysis <- read_csv("car_analysis.csv")

            #Linear Models and Transformations

carLm <- lm(price~mileage, data=car_analysis)
CarlmSqrt <- lm(sqrt(price)~mileage, data=car_analysis)

PredictedSell <- predict(CarlmSqrt, data.frame(mileage=220000))^2
bs <- coef(CarlmSqrt)

  #Graph begins

ggplot(data = car_analysis, mapping = aes(x = mileage, y = price)) +
  
  #Data Points
  
  geom_point(color = "grey35", fill = "grey", shape=21, size=2.4, alpha=.5) +
  
  # Transformed Model
  stat_function(fun = function(x) (bs[1] + (bs[2] * x))^2, color = "steelblue", linewidth = 1.2) +
  
  # Line Between Points
  geom_line(data = data.frame(mileage = c(128000, 220000), price = c(3300, PredictedSell)), 
            aes(x = mileage, y = price), color = "black", linewidth = 1, linetype = "dotted") + 
  
  # Predicted Points
  geom_point(aes(x = 128000, y = 3300), size = 6, shape = 21, fill = "darkseagreen", show.legend = F) +
  
  geom_point(data = data.frame(mileage = 220000, price = PredictedSell), 
             aes(x = mileage, y = price), size = 6, shape = 21, fill = "orange", show.legend = F)+
  
  # Text Labels for Predicted Points

geom_label(data = data.frame(x = 128000, y = 1600), aes(x = x, y = y, label = "Bought for $3,300"), size = 4) +
  
geom_label(data = data.frame(x = 220000, y = 2100), 
                 aes(x = x, y = y, label = "Estimated Sale of $3,682")) +
  
  # Customize Axes
  scale_x_continuous(breaks = seq(0, 250000, by = 50000), labels = c("0", "50,000", "100,000", "150,000", "200,000", "250,000")) +
  scale_y_continuous(breaks = seq(0, 20000, by = 5000), labels = c("0", "$5,000", "$10,000", "$15,000", "$20,000")) +
  
  # Labels and Theme
  labs(
    x = "Mileage",
    y = "Price",
    title = "Ford Fusion Prices by Mileage",
    col = "Transaction Points"
  ) +
  theme_classic() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, color="grey5"),
    axis.title = element_text(size = 12, color="grey15"),
    axis.text = element_text(size = 11, color="grey25"),
    plot.margin = margin(0.5, 0.5, 0.5, 0.5, "cm")
  )

```

<br>

Here is the graph of my transformed linear model. I initially made this prediction using a simple linear model (you can view it in the next tab). After setting it up, I performed a Box-Cox test to identify any recommended transformations. As expected, the test suggested a square root transformation (with a lambda of 0.54), resulting in the graph above. You can still see the original linear model as a light grey line in the background.

I want to emphasize that the purpose of this model is to predict a realistic selling price for my car. A good measure for this is the slope between the buying and selling points. This slope represents an increase in value per mile driven of **$0.0042**. This calculation comes from taking the difference in price between the selling and buying points and dividing it by the mileage difference.

Based on this, my predicted selling price could be of **$3,682**! Not bad, right? This model suggests that even if I sell my car after driving it for another 100,000 miles, I could still get around 300 dollars in return.

This transformed model makes sense to me because used cars rarely depreciate to zero; even when considered junk, they can be sold for parts, allowing you to recover some money.

Now, let's take a look at the statistical summary of the model.

<br>

```{r}
summary(CarlmSqrt) %>% 
  pander()
```

<br> 

In my opinion, things look good in this model's summary. With an R^2^ close to **.90** and both p values being low enough, it would be safe to trust the model's accuracy after checking if requirements are met in the diagnostics.

<br> <br>

### Original Linear Model

<br>

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', fig.width=10}

carLm <- lm(price~mileage, data=car_analysis)
PredictedSell2 <- predict(carLm, data.frame(mileage=220000))

ggplot(data = car_analysis, mapping = aes(x = mileage, y = price)) +
  
  # Linear Model
  geom_smooth(method = "lm", se = FALSE, color = "steelblue4", linewidth = 1.3) +
  
  #Data Points
  
  geom_point(color = "grey35", fill = "grey", shape=21, size=2, alpha=.5) +

  
  # Line Between Points
  geom_line(data = data.frame(mileage = c(128000, 220000), price = c(3300, PredictedSell2)), 
            aes(x = mileage, y = price), color = "black", linewidth = 1, linetype = "dotted") + 
  
  # Predicted Points
  geom_point(aes(x = 128000, y = 3300), size = 7, shape = 21, color= "darkgreen", fill = "darkseagreen", show.legend = F) +
  
  geom_point(data = data.frame(mileage = 220000, price = PredictedSell2), 
             aes(x = mileage, y = price), size = 7, shape = 21, color="orange4", fill = "orange", show.legend = F)+
  
  # Text Labels for Predicted Points

geom_label(data = data.frame(x = 128000, y = 1600), aes(x = x, y = y, label = "Bought for $3,300"), size = 4) +
  
geom_label(data = data.frame(x = 220000, y = 1100), 
                 aes(x = x, y = y, label = "Estimated Sale of $2,850")) +
  
  # Customize Axes
  scale_x_continuous(breaks = seq(0, 250000, by = 50000), labels = c("0", "50,000", "100,000", "150,000", "200,000", "250,000")) +
  scale_y_continuous(breaks = seq(0, 20000, by = 5000), labels = c("0", "$5,000", "$10,000", "$15,000", "$20,000")) +
  
  # Labels and Theme
  labs(
    x = "Mileage",
    y = "Price",
    title = "Ford Fusion Prices by Mileage",
    col = "Transaction Points"
  ) +
  theme_classic() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, color="grey5"),
    axis.title = element_text(size = 12, color="grey15"),
    axis.text = element_text(size = 11, color="grey25"),
    plot.margin = margin(0.5, 0.5, 0.5, 0.5, "cm")
  )
  
```

<br>

This is my original linear model. Notably, the slope of the line connecting my buying and selling points is negative, with a slope of **$0.0048** dollars per mile. 

Consequently, this model predicts a selling price of **$2,849.73**, which is almost $800 lower than the transformed model. While this amount is not insignificant, it’s important to consider factors that affect the data, such as the fact that cars don’t depreciate to zero and that the model may fit better for higher mileages.

I find it interesting that both predictions are close, yet there is a $800 difference between them, which could be quite significant.

Let's now review the statistical summary of this model.

<br>

```{r}
summary(carLm) %>% 
  pander()
```

<br> <br> 

In my opinion this model isn't bad as either, it has a nice R^2^ of **.87**. As well as significant P. values at the alpha level of .05.

I still prefer the transformed model because of how it fits the data in
a better way.

<br> <br>

### Transformations and Diagnostic Plots

####  {.tabset .tabset-fade}

##### Box Cox Transformation Process

<br>

To check for transformations possibilities I ran a Box Cox test on my linear model and got the next graph.

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}

boxcox_result <- boxcox(carLm)
```

At simple view we can guess that there is a .5 (Square Root) transformation suggested. I went ahead and checked my Lambda value and got a **0.55**. This confirmed a Square Root transformation would be appropriate. 

To apply this transformation, you need to take the square root of your Y values in the linear model and then adjust your model using the transformed Y intercept and slope, as shown below.

<br>

$$
\sqrt{\hat{Y_i}} = 1.434 \times 10^2 - 3.762 \times 10^{-4}X_i
$$

<br>

These results are used to plot the transformed line that fits your model. However, to convert your prediction results back to the original scale, you need to apply the inverse of the transformation used in your linear model, as shown below:

<br>

$$
\hat{Y_i} = (1.434 \times 10^2 - 3.762 \times 10^{-4}X_i)^2
$$

<br>

As you can see, to reverse the square root transformation we applied earlier, we now square the prediction results to return them to their original scale. This process aligns with the transformed model and helps achieve a better fit for your data and model.

<br> <br>

##### Transformed diagnostics

<br> 

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', fig.width=10}
par(mfrow=c(1,3))
plot(CarlmSqrt, which=1:2)
plot(CarlmSqrt$residuals)

```

<br>

The diagnostic plots for the transformed model look good to me. While there is a violation of normality, the plots for independence and variance appear satisfactory. This suggests that the transformed model can be trusted.

<br> <br>

##### Original diagnostics

<br>

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', fig.width=10}
par(mfrow=c(1,3))
plot(carLm,which=1:2)
plot(carLm$residuals)
```

<br>

The diagnostic plots for the original model look decent, but they show more issues compared to the transformed model. Although the original model is not completely untrustworthy, it reinforces that the transformed model is more reliable. Nevertheless, the original model is still acceptable.

<br> <br>

### Conclusion

<br>

I originally bought this car for $3,300. When I purchased it in 2021, it had 128,000 miles. It’s currently at 195,000 miles after 3 years. I expect to continue using it, even if I leave Rexburg. I’ll probably take it with me after graduation and use it a while longer. However, if the opportunity arises to sell it, I would consider this study.

If I sell it after reaching 220,000 miles, the transformed linear model predicts that the car would still be worth $1,000, even at 300,000 miles. This means I could recover about one-third of what I originally paid for it after over 4 years of use.

Overall, there is sufficient evidence to conclude that the models, particularly the transformed one, can be trusted in their predictions, given the current data.

<br> <br>
